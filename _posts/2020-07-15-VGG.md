---

layout: single
title:  "VGG"
header:
  teaser: ""
categories: 

  - Machine Learning
tags:
  - VGG
comments: True
---

# 2020.07.15

## VGG (2014) [Paper_link](https://arxiv.org/pdf/1409.1556.pdf)

- VGG 19, VGG 16?
    - VGG :  Visual Geometry Group
    - 19, 16 : Layers
- 특징
    - 매우 작은 Conv filter(3 x 3 사이즈)로 층을 깊게 구현한다
    - [7 x 7 Conv] = [3 x 3 Conv]  3개
        - 7x7 사이즈의 필터를 사용한다면 한 번의 Activation Function을 사용하지만 3x3사이즈의 필터를 세 번 사용하면 세번의 Activation Function을 사용할 수 있다.
        - 이렇게 하면 좀더 많은 비선형성을 얻을 수 있고, parameter수가 줄어든다 (parameter → 3x3x3 = 27 < 7x7 = 49)
- 구조

    ![Untitled](https://user-images.githubusercontent.com/48716219/90955149-0f4b5f00-e4b6-11ea-8b08-773168249215.png)

    - input은 224x224 사이즈의 RGB
        
        - 이때의 전처리는 특별한 것은 없고 각 픽셀에 RGB의 평균값을 빼주는 것 뿐
    - 1x1 Conv layer를 활용 ([추가 정보](https://hwiyong.tistory.com/45))
        - 비선형성을 증가시킨다
            - ReLU를 계속해서 사용하면 비선형성 증가
            - ReLU 사용목적은 비선형성을 더해주기 위함이다
            - **비선형성이 증가한다 = 복잡한 패턴을 좀 더 잘 인식할 수 있게 된다**
        - Input Channel = Output Channel

        +. 추가

        - 채널 수 조절

            input channel = output channel

        - 계산량 감소

            채널 수 조절은 곧 계산량의 감소고 네트워크를 구성할 때 좀 더 깊어질 수 있도록 도움을 준다

 - 2020.07.16

- Classification Framework
    - Weight Decay?

        [Regularization (Weight Decay)](https://deepapple.tistory.com/6)

    - Configuration
        - batch size = 256, momentum = 0.9
        - regularised by weght decay ( L2 penalty multiplier set to $5*10^{-4}$)
            - Regularization이란 과적합(Overfitting)을 제어를 위해 가장 많이 사용되고 있는 일반화 기법
            - 가중치( Weights )가 클수록 큰 페널티( Penalty )를 부여하는 기법
            - 즉, 가중치가 너무 큰 값을 가지지 못하게 방해하여 과적합을 조절하는 것
        - Dropout = 처음 두개의 FC Layers에 0.5 적용
        - Learning rate = 처음에는 0.01로 설정, Validation Accuracy 오르는 것이 멈출 때 감소시킨다
        - 네트워크 가중치의 초기화가 중요
            - VGG-11에서 일단 랜덤하게 초기화하고 충분히 학습 시킨다
            - 첫 4개의 Conv layer와 마지막 3개의 FC layer에 초기화를 적용 (인접한 layer는 랜덤, 정규분포에 따른 Weight)
            - Bias = 0
    - Training image size
        - S를 입력 받는 이미지의 짧은 부분을 뜻한다

            S는 **isotropically-rescaled**된 ConvNet 입력으로 잘려진 훈련 이미지의 가장 작은 측면

            isoptropically-rescaled = 이미지의 사이즈는 바뀌더라도 가로세로비는 일정한 것

        - 네트워크에서 input은 224x224로 고정해서 받기 때문에 image의 크기를 가로, 세로 비율에 맞춰서 조정하고 랜덤한 범위를 224x224로 잘라서 학습시킨다.
        이때 조정된 이미지의 짧은 변은 S
        - 크게 두 종류로 학습, Single-scale / Multi-scale
        1. Single Scale

            먼저 S=256, 이후에 속도를 올리기위해 S=384로 학습
            S=384로 학습할 때 learning rate 는 0.001을 사용

        2. Multi Scale

            학습 이미지를 각각 S가 256~512사이에서 랜덤한 값을 갖도록 rescale

            이미지의 object들은 다양한 사이즈가 되기 때문에 학습하는데 더 좋다

            이 방식은 'Scale Jittering'이라고 부른다.
            학습을 반복함에 따라 하나의 이미지를 다양한 스케일로 학습하게 됨, 그렇게 되면 Training set이 augmentation된다.