---

layout: single
title:  "ZFNet"
header:
  teaser: ""
categories: 

  - Machine Learning
tags:
  - ZFNet
comments: True
---


# 2020.07.10

## ZFNet (2013) [Paper Link](https://arxiv.org/pdf/1311.2901.pdf)

- CNN을 보다 잘 이해하기 위해 "Visualizing 기법"을 사용
- ZFNet은 특정 구조를 가리키는 개념이 아니라, CNN을 보다 잘 이해할 수 있는 기법을 가리키는 개념
- 새로운 구조를 발표했다기 보다는 AlexNet의 기본 구조를 Visualizing 기법을 통해 개선할 수 있다는 것을 보여줌
- AlexNet을 기반으로 첫 Conv layer의 filter size를 11→7, stride를 4 → 2로 바꿨음
- ablation study : 모델이나 알고리즘의 특성을 제거해가면서 그게 퍼포먼스에 어떠한 영향을 끼치는지 확인하는 방법
- 시각화 기술

    ![Untitled](https://user-images.githubusercontent.com/48716219/90332762-c64d6380-dffa-11ea-8b5e-3de0aebf85d8.png)

    - 위의 그림

        왼쪽은 DeconvNet을 표현한것이고 오른쪽은 ConvNet을 표현한 것이다. DeconvNet은 ConvNet에서 나온 Feature를 통해 대략적으로 재구성할 것이다.

    - 아래 그림

        ConvNet에서 MaxPooling을 수행하면서 각 지역의 최대값을 표시하는 'switches'를 만들고, 이것을 DeconvNet에서 UnPooling할 때 활용한다

    - 추가 내용

        switch를 사용해서 가장 강한 자극의 위치를 정확하게 찾아가지만 MaxPooling을 거치면서 강한 자극을 제외한 나머지 자극들은 복원할 수가 없다.

    - Layer 1, 2

        ![Untitled 1](https://user-images.githubusercontent.com/48716219/90332767-d06f6200-dffa-11ea-9492-88798b142fdf.png)

        주로 영상의 코너, edge 혹은 color와 같은 low level feature를 시각화

        +. low level feature? high level feature?

        [Sung Kim](https://www.facebook.com/groups/TensorFlowKR/permalink/550916028582793/)

    - Layer 3

        ![Untitled 2](https://user-images.githubusercontent.com/48716219/90332769-d5ccac80-dffa-11ea-867a-65a546a0fa76.png)

        층이 깊어질수록 더 복잡한 (상위 수준) 항상성(invariance)을 얻을 수 있거나 비슷한 외양(texture)를 갖고 있는 특징을 추출할 수 있다.

    - Layer 4

        ![Untitled 3](https://user-images.githubusercontent.com/48716219/90332772-dcf3ba80-dffa-11ea-9d9e-ee27c44cd12a.png)

        사물이나 개체의 일부분을 볼 수 있다. (강아지 사진)

    - Layer 5

        ![Untitled 4](https://user-images.githubusercontent.com/48716219/90332781-e715b900-dffa-11ea-827f-b5dc11015fb6.png)

        위치나 자세 변화 등까지 포함한 사물이나 개체의 전부를 보여준다

- 구조

    ![Untitled 5](https://user-images.githubusercontent.com/48716219/90332784-eed55d80-dffa-11ea-8bed-26fd74f7e738.png)

    AlexNet의 filter size : 11 , stride : 4 → ZFNet filter size : 7, stride : 2

    architecture에 집중하기 보다는, 학습이 진행됨에 따라 feature map을 시각화하는 방법과, 모델이 어느 영역을 보고 예측을 하는지 관찰하기 위한 Occlusion 기반의 attribution 기법 등 시각화 측면에 집중

- 정리
    - 시각화를 수행하면?
        - 특정 단계에서 얻어진 Feature map이 고르게 확보되었는지, 혹은 특정 feature에 쏠려 있는지 확인 가능
        - 학습의 결과에 대한 정도를 파악할 수 있다.
        - 최종적으로 CNN의 구조가 적절한지 판단하기 좋음
    - Visualization 기법
        - 시각화를 위해 Deconvolution 사용
        - MaxPooling → UnPooling 과정에서 Switch 개념 적용
    - 중간 중간에 각 층에서 feature가 원영상의 어떤 영역에 해당하는지, layer가 올라감에 따라서 local feature → global feature로 바뀌는 것에 대해서도 이해하기 쉽다.

- 참고

[[Part Ⅴ. Best CNN Architecture] 4. ZFNet [1] - 라온피플 머신러닝 아카데미 -](https://m.blog.naver.com/PostView.nhn?blogId=laonple&logNo=220673615573&proxyReferer=https:%2F%2Fwww.google.com%2F)

![Untitled 6](https://user-images.githubusercontent.com/48716219/90332790-f72d9880-dffa-11ea-8500-0d332cd95e29.png)